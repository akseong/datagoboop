---
title: "First look "
date: "`r format(Sys.time(), '%d %B %Y')`"
header-includes:
  - \usepackage{bm}
  - \usepackage{xcolor}
  - \usepackage{amssymb}
output: 
  html_document:
    df_print: paged
    theme: flatly
    highlight: tango #pygments
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
    smooth_scroll: true
    code_fold: hide
  urlcolor: blue
---
  

```{r setup, include=FALSE, message=F, echo=F, warning=F}
# LIBRARIES----
library(tidyverse)
library(gridExtra)
library(here)
library(knitr)


# DOCUMENT SETUP ----
# detect pdf/html output, set chunk options, sci.notation 
latex_out <- knitr::is_latex_output()
knitr::opts_chunk$set(cache=F, 
                      message=F, 
                      echo=!latex_out, 
                      warning=F, 
                      fig.height=4, 
                      fig.width=6)


# PLOTTING FCNS----
# default settings; transparency for base R
pardefault <- par(no.readonly=T)
palramp <- colorRampPalette(c("deepskyblue", "purple", "orangered"))
transp_pal <- function(pal, alpha=75){
  # add transparency to palette 'pal'
  return( rgb(t(col2rgb(pal)), alpha = alpha, maxColorValue = 255) )
} 

#ggplot2 colors into base R
gg_color <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}



# SIGNAL/PROCESSING ----
# Apply affine transformation to y so that max(y) = 1 and min(y) = -1
# We'll need this later to make sure input to play() is valid
# Anything above +1/below -1 will be clipped, resulting in distortion
wave_norm <- function(y) {
  bias = mean(y)
  y <- y - bias
  M <- max(y)
  m <- min(y)
  scale <- if (M > abs(m)) M else abs(m)
  y <- y / scale
  return(y)
}




# TEXT/TABLE FORMATTING----
colorize <- function(x, color="red") {
  # text color conditional on latex/html output
  # from rmarkdown cookbook
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{ %s}{ %s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color, x)
  } else x
}

# kable NA handling
options(knitr.kable.NA = '')

# mykable function
mykable <- function(tab, cap,
                    latex_options=c("hold_position", "scale_down", "striped"), 
                    bootstrap_options=c("striped", "hover", "condensed"), 
                    full_width=F, position="center", ...){
  # kable formatting conditional on latex or html output
  if (knitr::is_latex_output()){
    kable(x=tab, caption=cap, ...) %>%
      kableExtra::kable_styling(latex_options = latex_options)
  } else if (knitr::is_html_output()){
    kable(x=tab, caption=cap, ...) %>%
      kableExtra::kable_styling(bootstrap_options = bootstrap_options, full_width=full_width, position=position)
  }
}

# SOURCE common functions ----
# make a %notin% function to mirror %in%
`%notin%` <- Negate(`%in%`)
```










# `audio` package

## fooling around

play a pitch, same pitch plus another

```{r foolin}
library(audio)

pal <- transp_pal(palramp(4), alpha = 175)
palette(pal)

# continuous pitch
s1 <- sin(1:88000/10)
plot(s1[1:500], pch=',', main = "wave `s1`", col=1)
play(s1)

# another continuous pitch
s2 <- sin(1:88000/20)
plot(s2[1:500], pch=',', main = "wave `s2`", col=1)
play(s2)


# play together
plot(c(s1+s2)[1:500], pch=',', main = "wave s1 + s2", col=1)
play(wave_norm(s1 + s2))

# 2 sec white noise
wn <- rnorm(88000, 0, 1)
plot(wn[1:500], pch=',', col=1)
play(wave_norm(wn))

# adding sound wave to white noise
play(wave_norm(s1 + wn))

```





## middle A (A4)

1 second = 44.1k length vector

middle A: 44o Hz.  i.e. need to cycle through 2pi every 100 elements?

```{r middleA}
# 1 second of A4
mid_a <- sin(rep(seq(0, 2*pi,length.out=100), 440))
play(mid_a)
```



## Piano key frequencies

[Piano key frequencies](https://en.wikipedia.org/wiki/Piano_key_frequencies) gives us a mapping from the key number on a standard piano to hz_:

$$f(n) = 2^{\frac{n-49}{12}} \times 440 \text{ Hz}$$



## Pure tones

The standard parameterization for a [pure tone](https://en.wikipedia.org/wiki/Pure_tone) is
$$y(t) = A\sin (2 \pi f t + \phi),$$
where

* $A$ is the amplitude of the tone, which corresponds to loudness and should be chosen so that $y(t)$ is bounded between $[-1, 1]$,
* $f$ is the frequency of the tone in Hz, which corresponds to pitch and should be within the interval $(\approx 20, \approx 20000)$ to be audible,
* $t$ is the current time in seconds, and
* $\phi$ is the phase shift of the sound, which should be within $[0, 2\pi]$. For our purposes we can usually assume this to be zero.



__Write some functions:__

+ `pkey_to_hz(keynum)` maps piano key number to Hz
+ `hz_to_1sec(hz)` generates a one-second sine wave
+ `note(pkey, vol=1)` combines them, adds volume multiplier (amplitude = volume).  
  + can feed `note()` output directly into `play()` from `audio` package. 


```{r basic_funcs}
pkey_to_hz <- function(keynum){
  # maps piano key to hz
  2^((keynum-49) / 12) * 440
}

hz_to_1sec <- function(hz, fs = 44100){
  # Generate time steps spanning 1 seconds
  # Note that fs is the "sampling frequency" i.e., the number of elements in the vector played over 1 second
  # For most systems, this is either 44100 Hz or 48000 Hz
  t <- seq(0, 1, 1/fs)
  
  # Return the sine wave
  sin(2 * pi * hz * t)
}

hz_to_sec <- function(hz, dur = 1, fs = 44100){
  # Generate time steps spanning 1 seconds
  # Note that fs is the "sampling frequency" i.e., the number of elements in the vector played over 1 second
  # For most systems, this is either 44100 Hz or 48000 Hz
  t <- seq(0, dur, 1/fs)
  
  # Return the sine wave
  sin(2 * pi * hz * t)
}

note <- function(pkey, vol=1, dur = 1){
  #cap volume to prevent clipping
  V = min(abs(c(vol,1)))
  
  # combines basic funcs to output playable vectors
  V*hz_to_sec(hz = pkey_to_hz(keynum = pkey), dur)
}

#function to create waves for a sequence of notes
note_seq <- function(pkey, vol = 1, total_dur = 1){
  
  l <- length(pkey)
  vlength <- length(vol)
  
  
  if( vlength > 1){
    #Error catching
    if(vlength != l){
      stop('if vol is not of length 1, vol must be of the same length as pkey')
    }
  }
  else{
    vol = rep(vol, l)
  }
  
  #Hard thresholding at 1
  V = pmin(abs(vol),1)
  
  #Concatenating waves
  ret_wave = V[1]*hz_to_sec(hz = pkey_to_hz(keynum = pkey[1]), total_dur/l)
  for(i in 2:l){
    ret_wave = c(ret_wave, V[i]*hz_to_sec(hz = pkey_to_hz(keynum = pkey[i]), total_dur/l))
  }
  
  return(ret_wave)
}


```



__Test:__

```{r play_basic}
play(
  hz_to_sec(pkey_to_hz(49),0.1)
)
play(note(49, 1, 0.1))
play(note(49, .25))
play(note(49, .1))


```





## play an A major scale

_Done:_ Needed to revamp function generating 44k length vector of specified hz because

+ rep() didn't vectorize well
+ rep() needed integer-valued arguments


```{r}
# Notes of the A scale
Ascale <- c(49, 51, 53, 54, 56, 58, 60, 61)

# Concatenate the sine waves
y_t <- c()
for (f in Ascale) {
  y_t <- c(y_t, note(f,1,0.3))
}

# Play
play(y_t)

# Maybe another way to do the above that doesn't take so much memory
#Though there is clipping in this approach
for(f in Ascale){
  wait(play(note(f,1,0.3))) #Wait will let the current sound finish playing before it starts the next one
}


```

__Hey, it works!!__



We can make amplitude $A$ a function of $t$ to create dynamic changes in volume. Here's one where the amplitude has an exponential decay.

```{r}
# Get the unmodulated tone
y_t <- note(49)

# Generate an amplitude mask of the same length
A <- exp(-6 * (1:length(y_t))/44100)

# Multiply and play
y_t <- A * y_t
play(y_t)
```


Trying out chords
```{r}
# Chords are sums of sines. Be sure to apply wave_norm so that the waveform stays between [-1, 1]
Amaj <- wave_norm(note(Ascale[1]) + note(Ascale[3])   + note(Ascale[5]))
Amin <- wave_norm(note(Ascale[1]) + note(Ascale[3]-1) + note(Ascale[5]))

# Play (should be played separately)
play(Amaj)
play(Amin)


#function to take in notes and output the wave for a chord
chord <- function(notes, vol = 1, dur = 1){
  
  waves = note(notes[1], vol, dur)
  for(i in 2:length(notes)){
    waves = waves + note(notes[i], vol, dur)
  }
  
  wave_norm(waves)
}

Amaj = chord(c(Ascale[1], Ascale[3], Ascale[5]), 1, 0.5)
play(Amaj)

```



# Repitching pre-recorded sounds

To make compelling music, we'll likely need to incorporate pre-recorded sounds, and we would like to be able to adjust the pitch of pre-recorded sounds. The simplest method for doing this is called "re-pitching" or "time stretching." The idea is to speed up or slow down the pre-recorded sounds by a factor necessary to achieve the desire pitch shift.

__Here's a function to do that__ :

+ `repitch` takes a single-channel (mono) waveform `y` and shifts it by `shift` semitones (may be positive or negative, or non-integer).

```{r repitch}
repitch <- function(y, shift) {
  t_old <- seq(0, 1, length.out = length(y))
  t_new <- seq(0, 1, length.out = round(length(y) / 2^(shift / 12)))
  return(approx(t_old, y, t_new)$y)
}
```

```{r repitch-example}
# Load piano and snare sounds
snr <- load.wave(here::here("sounds", "snare.wav"))
pC4 <- load.wave(here::here("sounds", "piano_C4.wav"))

# Note that they're stereo sounds (both 2 x N).
# For simplicity, let's convert to mono (1 x N), but note that we can get a lot of interesting effects with stereo
# Also, crop the piano sample (it's very long)
snr <- snr[1, ]
pC4 <- pC4[1, 1:(44100/2)]

# Sequence of snares increasing in pitch
snr_seq <- c()
for (k in 1:13) {
  snr_seq <- c(snr_seq, repitch(snr, k))
}
play(snr_seq)

# Sequence of piano notes decreasing chromatically in pitch
pno_seq <- c()
for (k in rev(1:13)) {
  pno_seq <- c(pno_seq, repitch(pC4, k))
}
play(pno_seq)
```






# Reverb and filters

Both reverb and filters (high-pass, low-pass, band-pass) can be achieved by convolving the waveform with an appropriate kernel.  In some cases, the processing can be sped up by using the fast Fourier transform (FFT) and working in the frequency domain instead of time domain.  I haven't worked with either inside of R, so no examples yet.



# `tuneR` package





# Translating data into sound
For our case study we should probably use the mtcars dataset.

## One-dimensional case
```{r}
data("mtcars")
y = mtcars$mpg

hist_inf <- hist(y, plot = FALSE)
breaks <- hist_inf$mids
vols <- hist_inf$counts/max(hist_inf$counts)


#Using volume as measure of relative requency of breaks
hist(y)
play(note_seq(2*breaks, vols, 2))


#Using pitch as measures of break counts
play(note_seq(hist_inf$counts*3, vols, 2))

```


### exponentiate vols?

Having a hard time hearing the difference in volume.  
+ I'm wondering if human perception of volume is logarithmic to amplitude?
+ lower pitches tend to be harder to pick out at lower volumes.  Not sure how to address this.


```{r}
vols2 <- (2^hist_inf$counts)/(2^max(hist_inf$counts))
play(note_seq(2*breaks, vols2, 2))
```




### variation 1: values --> pitch, counts --> duration

```{r counts_duration}
ggplot(mtcars) + 
  geom_histogram(aes(x=mpg), breaks = seq(10, 35, 5), alpha = .2, col=1) + 
  coord_flip() + 
  labs(title="can we mimic this?")

# I find I can't hear the difference in volume well enough for counts-->volume
# I do like the counts-->pitch
# An alternative might be:
# map break midpoints to pitch
# map counts to duration
fs = 44100
dur <- 5
breaks <- hist_inf$mids  
pkeys <- breaks*2  # separate pitches a little

# durations for each note (and silence afterwards)
wave_length <- dur*fs
dur_rel <- hist_inf$counts/max(hist_inf$counts) * dur
silence_length <- wave_length - dur_rel*fs

# construct each pitch + duration separately
wave_ret <- rep(0, wave_length)
for (i in 1:length(dur_rel)){
  wave_i <- c(note(pkey = pkeys[i], dur = dur_rel[i]),  # individual note with relative length
              rep(0, silence_length[i]))                # fill rest of duration with silence
  wave_ret <- wave_ret + wave_i[1:wave_length]
}

chrom <- wave_norm(wave_ret)
play(chrom)
```



```{r strums}
# strum at each change in the chord
strums <- dur_rel[order(dur_rel)]
seps_length <- c(strums[1], diff(strums)) * fs
Amp <- NULL
for (i in 1:length(seps_length)){
  Amp_i <- exp(-6 * (1:seps_length[i])/fs)
  Amp <- c(Amp, Amp_i)
}


chrom_strum <- wave_norm(Amp*wave_ret)
play(chrom_strum)
```



### variation 2: map to a scale

```{r histogram_in_A_major}
# map to a scale
pkeys <- c(Ascale[1],
           Ascale[3],
           Ascale[5],
           Ascale[8],
           Ascale[8] + 4)

# construct each pitch + duration separately
wave_ret <- rep(0, wave_length)
for (i in 1:length(dur_rel)){
  wave_i <- c(note(pkey = pkeys[i], dur = dur_rel[i]),  # individual note with relative length
              rep(0, silence_length[i]))                # fill rest of duration with silence
  wave_ret <- wave_ret + wave_i[1:wave_length]
}

Ach <- wave_norm(wave_ret) 
Ach_strum <- wave_norm(Amp*wave_ret)
play(Ach)
play(Ach_strum)
```



### variation 3: fill in the chord instead

```{r knock_knock}
# Seems clearest, but sounds like a door chime!
play(rev(Ach))
ggplot(mtcars) + 
  geom_histogram(aes(x=mpg), breaks = seq(10, 35, 5), alpha = .2, col=1) + 
  scale_y_reverse() + 
  coord_flip() + 
  labs(title="more like this")
```


```{r}
# I like how this sounds the best... but not as clear
play(rev(Ach_strum))
```



### variation 4: arpeggiate

```{r}
# arpeggio with different lengths
fs = 44100
max_dur <- .5
pkeys <- hist_inf$mids*2

# durations for each note
dur_rel <- hist_inf$counts/max(hist_inf$counts) * max_dur

# ascending only
wave_ret <- NULL
for (i in 1:length(dur_rel)){
  wave_i <- note(pkey = pkeys[i], dur = dur_rel[i])  # individual note with relative length
  wave_ret <- c(wave_ret, wave_i)
}
arpeg_asc <- wave_ret

# both ascending and descending with pauses
arpeg_both <- c(arpeg_asc,
                rep(0, fs/5),
                rev(arpeg_asc),
                rep(0, fs/5))



# classical arpeg
dur_both <- c(dur_rel, rev(dur_rel[-c(1, length(dur_rel))]))
pkeys_both <- c(pkeys, rev(pkeys[-c(1, length(pkeys))]))
wave_ret <- NULL
for (i in 1:length(dur_both)){
  wave_i <- note(pkey = pkeys_both[i], dur = dur_both[i])  # individual note with relative length
  wave_ret <- c(wave_ret, wave_i)
}
arpeg_class <- wave_ret


arpeg_times <- 3
play(rep(wave_norm(arpeg_asc), arpeg_times))    # ascending only
play(rep(wave_norm(arpeg_both), arpeg_times))   # both ascend/descend
play(rep(wave_norm(arpeg_class), arpeg_times))  # classical version (bottom/top not repeated)
```




### variation 5: violin audioplot

```{r}
# map to a scale
pkeys <- Ascale[1:length(breaks)]

# construct each pitch + duration separately
wave_ret <- rep(0, wave_length)
for (i in 1:length(dur_rel)){
  wave_i <- c(note(pkey = pkeys[i], dur = dur_rel[i]),  # individual note with relative length
              rep(0, silence_length[i]))                # fill rest of duration with silence
  wave_ret <- wave_ret + wave_i[1:wave_length]
}

viol <- wave_norm(c(rev(wave_ret), wave_ret))
play(viol)
```



#### violinplot with more bins:

Just a normal distribution, values mapped to a regular major scale

```{r more_bins}
y <- rnorm(1000, 40, 5)
hist_inf <- hist(y, breaks = seq(floor(min(y)), floor(max(y))+1, length.out=16))
breaks <- hist_inf$mids
major_scale_intervals <- c(2, 2, 1, 2, 2, 2, 1)
large_scale <- c(0, 
           0 + cumsum(major_scale_intervals), 
           12 + cumsum(major_scale_intervals), 
           24 + cumsum(major_scale_intervals)) +40

pkeys <- large_scale[1:length(breaks)]

fs <- 44100
dur <- 5
wave_length <- dur*fs
dur_rel <- hist_inf$counts/max(hist_inf$counts) * dur
silence_length <- wave_length - dur_rel*fs

# construct each pitch + duration separately
wave_ret <- rep(0, wave_length)
for (i in 1:length(dur_rel)){
  wave_i <- c(note(pkey = pkeys[i], dur = dur_rel[i]),  # individual note with relative length
              rep(0, silence_length[i]))                # fill rest of duration with silence
  wave_ret <- wave_ret + wave_i[1:wave_length]
}
viol2 <- wave_norm(c(rev(wave_ret), wave_ret))
play(viol2)
```






# code wishlist (brainstorming question)

+ way to eliminate clicking between sounds
    + Is this a result of the speaker driver snapping between (relatively) distant positions / can it be smoothed?
    
+ re-pitch without changing length of sound
    + easy for simple sound (copy paste to fill vector)
    + seems harder for more complex sounds
    
+ functions to map data characteristics to:
    + pitches
    + volume
    + duration/speed
    + instruments
    + tempo

+ building in a few scales might be nice



# thoughts/questions
+ what could an audio scatterplot look like?










